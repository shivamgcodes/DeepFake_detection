{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3134515,"sourceType":"datasetVersion","datasetId":1909705},{"sourceId":7802761,"sourceType":"datasetVersion","datasetId":4568571}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n!pip install facenet-pytorch\n!pip install gradio==3.50\nfrom facenet_pytorch import MTCNN, InceptionResnetV1\n!pip install facenet_pytorch\nimport torch\nimport torch.nn.functional as F\nfrom facenet_pytorch import MTCNN, InceptionResnetV1\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport gradio as gr\n!pip install captum\nfrom captum.attr import IntegratedGradients\nfrom captum.attr import visualization as viz\nfrom captum.attr import InterpretableInput\nimport tqdm as tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download and Load Model","metadata":{}},{"cell_type":"code","source":"DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\nmtcnn = MTCNN(\n    select_largest=False,\n    post_process=False,\n    device=DEVICE\n).to(DEVICE).eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = InceptionResnetV1(\n    pretrained=\"vggface2\",\n    classify=True,\n    num_classes=1,\n    device=DEVICE\n)\n\n#checkpoint = torch.load(\"epoch28deepfake_detection.pt\", map_location=torch.device('cpu'))\n#model.load_state_dict(checkpoint['model_state_dict'])\nmodel.to(DEVICE)\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Inference ","metadata":{}},{"cell_type":"code","source":"def predict(input_image:Image.Image):\n    \"\"\"Predict the label of the input_image\"\"\"\n    face = mtcnn(input_image)\n    if face is None:\n        raise Exception('No face detected')\n    \n    face = face.unsqueeze(0) # add the batch dimension\n    \n    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n    \n    # convert the face into a numpy array to be able to plot it\n    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n    prev_face = prev_face.astype('uint8')\n\n    face = face.to(DEVICE)\n    face = face.to(torch.float32)\n    face = face / 255.0\n    print(face.size())\n    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n\n\n    output = 1\n    with torch.no_grad():\n        output = torch.sigmoid(model(face).squeeze(0))\n        prediction = \"real\" if output.item() < 0.5 else \"fake\"\n        \n        real_prediction = 1 - output.item()\n        fake_prediction = output.item()\n        \n        confidences = {\n            'real': real_prediction,\n            'fake': fake_prediction\n        }\n    ig = IntegratedGradients(model)\n    attributions = ig.attribute(face, n_steps=200 , target = 0  )\n    attributions = attributions.squeeze().permute(1, 2, 0).cpu().detach().numpy()\n    face = face.squeeze().permute(1, 2, 0).cpu().detach().numpy()\n    fig = viz.visualize_image_attr(attributions , face , 'original_image')\n    fig = viz.visualize_image_attr(attributions , face , 'alpha_scaling')\n    \n    \n    return confidences\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradio Interface","metadata":{}},{"cell_type":"code","source":"\ninterface = gr.Interface(\n    fn=predict,\n    inputs=[\n        gr.Image(label=\"Input Image\", type=\"pil\")\n    ],\n    outputs=[\n        gr.Label(label=\"Class\"),\n      \n    ],\n).launch(share = True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#from torchvision.io import read_image \n#print(predict(Image.open(\"/kaggle/input/deepfake-and-real-images/Dataset/Train/Fake/fake_10000.jpg\")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_from_model(threshold , model_output):\n    if(model_output > threshold):\n        return 1\n    return 0\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(y_pred, y_true):\n    correct = (y_pred == y_true).sum().item()\n    total = y_true.size(0)\n    return correct / total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision(y_pred, y_true):\n    true_positives = ((y_pred == 1) & (y_true == 1)).sum().item()\n    false_positives = ((y_pred == 1) & (y_true == 0)).sum().item()\n    return true_positives / (true_positives + false_positives + 1e-8)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall(y_pred, y_true):\n    true_positives = ((y_pred == 1) & (y_true == 1)).sum().item()\n    false_negatives = ((y_pred == 0) & (y_true == 1)).sum().item()\n    return true_positives / (true_positives + false_negatives + 1e-8)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_pred, y_true):\n    prec = precision(y_pred, y_true)\n    rec = recall(y_pred, y_true)\n    return 2 * (prec * rec) / (prec + rec + 1e-8)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}